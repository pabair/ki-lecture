{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for Classifying Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook follows in large parts  the notebook from Sean Robertson which you can find here:`<https://github.com/spro/practical-pytorch>`\n",
    "\n",
    "We will be building and training a basic character-level RNN to classify\n",
    "words. A character-level RNN reads words as a series of characters -\n",
    "outputting a prediction and \"hidden state\" at each step, feeding its\n",
    "previous hidden state into each next step. We take the final prediction\n",
    "to be the output, i.e. which class the word belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data\n",
    "\n",
    "Download the data from here\n",
    "   ` <https://download.pytorch.org/tutorial/data.zip>`\n",
    "   and extract it to the `data` directory.\n",
    "\n",
    "Included in the ``data/names`` directory are 18 text files named as\n",
    "``[Language].txt``. Each file contains a bunch of names, one name per\n",
    "line, mostly romanized (but we still need to convert from Unicode to\n",
    "ASCII)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab is of size 57 and contains: abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "\n",
    "# these is the vocabulary we will use\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "print(f\"Vocab is of size {n_letters} and contains:\", all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slusarski\n",
      "Heute ist es schon hei\n"
     ]
    }
   ],
   "source": [
    "# we convert anything into ascii\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicodeToAscii('Ślusàrski'))\n",
    "print(unicodeToAscii('Heute ist es schön heiß'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 20074)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "all_categories = []\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for filename in glob.glob('./data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    for line in lines:\n",
    "        X.append(line)\n",
    "        y.append(category)\n",
    "    \n",
    "n_categories = len(all_categories)\n",
    "n_categories, len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data points: 16059\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Train data points:\", len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning Names into Tensors\n",
    "--------------------------\n",
    "\n",
    "Now that we have all the names organized, we need to turn them into\n",
    "Tensors to make any use of them.\n",
    "\n",
    "To represent a single letter, we use a \"one-hot vector\" of size\n",
    "``<1 x n_letters>``. A one-hot vector is filled with 0s except for a 1\n",
    "at index of the current letter, e.g. ``\"b\" = <0 1 0 0 0 ...>``.\n",
    "\n",
    "To make a word we join a bunch of those into a 2D matrix\n",
    "``<line_length x 1 x n_letters>``.\n",
    "\n",
    "That extra 1 dimension is because PyTorch assumes everything is in\n",
    "batches - we're just using a batch size of 1 here.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    index = all_letters.find(letter)\n",
    "    tensor[0][index] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for i, letter in enumerate(line):\n",
    "        index = all_letters.find(letter)\n",
    "        tensor[i][0][index] = 1\n",
    "    return tensor\n",
    "\n",
    "print(lineToTensor('Jones').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categoryToTensor(category):\n",
    "    index = all_categories.index(category)\n",
    "    return torch.tensor([index], dtype=torch.long)\n",
    "\n",
    "categoryToTensor(\"Korean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Network\n",
    "====================\n",
    "\n",
    "Before autograd, creating a recurrent neural network in Torch involved\n",
    "cloning the parameters of a layer over several timesteps. The layers\n",
    "held hidden state and gradients which are now entirely handled by the\n",
    "graph itself. This means you can implement a RNN in a very \"pure\" way,\n",
    "as regular feed-forward layers.\n",
    "\n",
    "This RNN module is just 2 linear layers which operate on an input and hidden state, with\n",
    "a LogSoftmax layer after the output.\n",
    "You can see the architecture here: https://i.imgur.com/Z2xbySO.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = 128 # number of hidden layer size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + self.hidden_size, self.hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + self.hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        combined = torch.cat((x, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run a step of this network we need to pass an input (in our case, the\n",
    "Tensor for the current letter) and a previous hidden state (which we\n",
    "initialize as zeros at first). We'll get back the output (probability of\n",
    "each language) and a next hidden state (which we keep for the next\n",
    "step).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0530, 0.0582, 0.0559, 0.0481, 0.0569, 0.0575, 0.0594, 0.0555, 0.0637,\n",
      "         0.0541, 0.0513, 0.0594, 0.0516, 0.0513, 0.0527, 0.0557, 0.0572, 0.0586]],\n",
      "       grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(n_letters, n_categories)\n",
    "\n",
    "x = letterToTensor('A')\n",
    "hidden = torch.zeros(1, 128)\n",
    "\n",
    "output, next_hidden = rnn(x, hidden)\n",
    "print(torch.softmax(output, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the output is a ``<1 x n_categories>`` Tensor, where\n",
    "every item is the likelihood of that category (higher is more likely).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Network\n",
    "--------------------\n",
    "\n",
    "Now all it takes to train this network is show it a bunch of examples,\n",
    "have it make guesses, and tell it if it's wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just have to run that with a bunch of examples. Since the\n",
    "``train`` function returns both the output and loss we can print its\n",
    "guesses and also keep track of loss for plotting. Since there are 1000s\n",
    "of examples we print only every ``print_every`` examples, and take an\n",
    "average of the loss.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss in epoch 1 is 1.4326586759991504\n",
      "Loss in epoch 2 is 1.120601071009915\n",
      "Loss in epoch 3 is 1.0140432447121082\n",
      "Loss in epoch 4 is 0.9546429199808357\n",
      "Loss in epoch 5 is 0.9156462216209961\n",
      "Loss in epoch 6 is 0.888426669554454\n",
      "Loss in epoch 7 is 0.866464189422653\n",
      "Loss in epoch 8 is 0.8495533251452998\n",
      "Loss in epoch 9 is 0.8349207292691623\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=0.005)\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    \n",
    "    for i in range(0, len(X_train)):\n",
    "        hidden = rnn.initHidden()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        line = X_train[i] # Baarle\n",
    "        line_tensor = lineToTensor(line)\n",
    "        \n",
    "        category = y_train[i] # Dutch\n",
    "        category_tensor = categoryToTensor(category)\n",
    "        \n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "        loss = criterion(output, category_tensor)\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "    \n",
    "        current_loss += loss.item()\n",
    "\n",
    "    all_losses.append(current_loss)\n",
    "    print(f\"Loss in epoch {epoch} is {current_loss/len(X_train)}\")\n",
    "    current_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the Results\n",
    "--------------------\n",
    "\n",
    "Plotting the historical loss from ``all_losses`` shows the network\n",
    "learning:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9db0164040>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.753175591531756\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(0, len(X_test)):\n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    line = X_test[i]\n",
    "    line_tensor = lineToTensor(line)\n",
    "\n",
    "    category = y_test[i]\n",
    "    category_tensor = categoryToTensor(category)\n",
    "\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    \n",
    "    prediction = torch.argmax(output, 1).item()\n",
    "    category_index = all_categories.index(category)\n",
    "    \n",
    "    if category_index == prediction:\n",
    "        correct += 1\n",
    "    \n",
    "print(\"Accuracy: \", correct/len(X_test))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running on User Input\n",
    "---------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Dovesky\n",
      "(0.89) Russian\n",
      "(0.04) English\n",
      "(0.04) Czech\n",
      "(0.02) Polish\n",
      "(0.00) Greek\n",
      "\n",
      "> Jackson\n",
      "(0.64) English\n",
      "(0.20) Russian\n",
      "(0.05) Scottish\n",
      "(0.02) Greek\n",
      "(0.02) Czech\n",
      "\n",
      "> Satoshi\n",
      "(0.42) Japanese\n",
      "(0.20) Arabic\n",
      "(0.09) Russian\n",
      "(0.08) Polish\n",
      "(0.06) Italian\n"
     ]
    }
   ],
   "source": [
    "def predict(input_line, n_predictions=5):\n",
    "    print('\\n> %s' % input_line)\n",
    "    \n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    line_tensor = lineToTensor(input_line)\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "\n",
    "    # Get top N categories\n",
    "    output = torch.softmax(output, 1)\n",
    "    topv, topi = output.topk(n_predictions, 1, True)\n",
    "    for i in range(n_predictions):\n",
    "        value = topv[0][i].item()\n",
    "        category_index = topi[0][i].item()\n",
    "        print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "\n",
    "predict('Dovesky')\n",
    "predict('Jackson')\n",
    "predict('Satoshi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
